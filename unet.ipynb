{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_base_block(input_tensor,filters,kernal_size,activation='relu',batch_normalization=True):\n",
    "    x = inputs_tensor\n",
    "    x = layers.Conv2D(filters=filters,kernal_size=kernal_size,padding='same',kernal_initializer='he_normal')(x)\n",
    "    \n",
    "    if batch_normalization:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv2D(filters=filters,kernal_size=kernal_size,padding='same',kernal_initializer='he_normal')(x)\n",
    "    \n",
    "    if batch_normalization:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unet(image_tensor,n_filter=16,drop_out=0.1,batch_normalization =True):\n",
    "    \n",
    "    x = image_tensor\n",
    "    \n",
    "    # encoding/reduction section\n",
    "    \n",
    "    conv1 = encoding_base_block(input_tensor = x,filters=n_filters*1,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    pool1 = layers.MaxPool2D((2, 2))(conv1)\n",
    "    pool1 = layers.Dropout(dropout)(pool1)\n",
    "    \n",
    "    conv2 = encoding_base_block(input_tensor = pool1,filters=n_filter*2,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    pool2 = layers.MaxPool2D((2,2))(conv2)\n",
    "    pool2 = layers.Dropout(dropout)(pool2)\n",
    "    \n",
    "    conv3 = encoding_base_block(input_tensor = pool2,filters=n_filter*4,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    pool3 = layers.MaxPool2D((2,2))(conv3)\n",
    "    pool3 = layers.Dropout(dropout)(pool3)\n",
    "    \n",
    "    conv4 = encoding_base_block(input_tensor = pool3,filters=n_filter*8,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    pool4 = layers.MaxPool2D((2,2))(conv4)\n",
    "    pool4 = layers.Dropout(dropout)(pool4)\n",
    "    \n",
    "    conv5 = encoding_base_block(input_tensor=pool4,filters=n_filter*16,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    \n",
    "    up6 = layers.Conv2DTranspose(n_filters*8,(3,3),strides=(2,2),padding='same')(conv5)\n",
    "    up6 = layers.concatenate([up6,conv4])\n",
    "    up6 = layers.Dropout(drop_out)(up6)\n",
    "    conv6 = encoding_base_block(input_tensor=up6,filters=n_filter*8,kernal_size=(3,3),batch_normalization=batch_normalization)\n",
    "    \n",
    "    \n",
    "    up7 = layers.Conv2DTranspose(n_filters*4,(3,3),strides=(2,2),padding='same')(conv6)\n",
    "    up7 = layers.concatenate([up7,conv3])\n",
    "    up7 = layers.Dropout(drop_out)(up7)\n",
    "    conv7 = encoding_base_block(input_tensor=up7,filters=n_filter*4,kernal_size=(3,3),batch_normalization=batch_normalization)\n",
    "    \n",
    "    up8 = layers.Conv2DTranspose(n_filters*2,(3,3),strides=(2,2),padding='same')(conv7)\n",
    "    up8 = layers.concatenate([up8,conv2])\n",
    "    up8 = layers.Dropout(drop_out)(up8)\n",
    "    conv8 = encoding_base_block(input_tensor=up8,filters=n_filter*2,kernal_size=(3,3),batch_normalization=batch_normalization)\n",
    "    \n",
    "    \n",
    "    up9 = layers.Conv2DTranspose(n_filters*2,(3,3),strides=(2,2),padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9,conv1])\n",
    "    up9 = layers.Dropout(drop_out)(up9)\n",
    "    conv9 = encoding_base_block(input_tensor=up9,filters=n_filter,kernal_size=(3,3),batch_normalization=batch_normalization)\n",
    "    \n",
    "    \n",
    "    outputs = layers.Conv2D(1,(1,1),activation='sigmoid')(conv9)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = [image_tensor],outputs = [outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_train(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open('C:\\\\Users\\\\tayyabm\\\\Downloads\\\\oxford_cats_segmentation\\\\annotations\\\\trimaps\\\\Abyssinian_1.png')\n",
    "im2 = Image.open('C:\\\\Users\\\\tayyabm\\\\Downloads\\\\oxford_cats_segmentation\\\\images\\\\Abyssinian_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['x_col','y_col']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "trainval_path = 'C:\\\\Users\\\\tayyabm\\\\Downloads\\\\oxford_cats_segmentation\\\\annotations\\\\trainval.txt'\n",
    "f = open(trainval_path,'r')\n",
    "image_names = []\n",
    "for i in f:\n",
    "    image_name = i.split(' ')[0]\n",
    "    image_names.append(['images\\\\'+ image_name + '.jpg','annotations\\\\trimaps\\\\' + image_name+'.png'])\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(image_names,columns = columns)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3680 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:\\\\Users\\\\tayyabm\\\\Downloads\\\\oxford_cats_segmentation'\n",
    "train_image_generator = ImageDataGenerator().flow_from_dataframe(dataframe=df,x_col='x_col',y_col='y_col',directory=directory,class_mode='raw')\n",
    "train_mask_generator = ImageDataGenerator().flow_from_dataframe(dataframe=df,x_col='y_col',y_col='y_col',directory=directory,class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET with Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
