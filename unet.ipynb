{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_base_block(input_tensor,filters,kernal_size,activation='relu',batch_normalization=True):\n",
    "    x = inputs_tensor\n",
    "    x = layers.Conv2D(filters=filters,kernal_size=kernal_size,padding='same',kernal_initializer='he_normal')(x)\n",
    "    \n",
    "    if batch_normalization:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv2D(filters=filters,kernal_size=kernal_size,padding='same',kernal_initializer='he_normal')(x)\n",
    "    \n",
    "    if batch_normalization:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unet(image_tensor,n_filter=16,drop_out=0.1,batch_normalization =True):\n",
    "    \n",
    "    x = image_tensor\n",
    "    \n",
    "    # encoding/reduction section\n",
    "    \n",
    "    conv1 = encoding_base_block(input_tensor = x,filters=n_filters*1,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    pool1 = layers.MaxPool2D((2, 2))(conv1)\n",
    "    pool1 = layers.Dropout(dropout)(pool1)\n",
    "    \n",
    "    conv2 = encoding_base_block(input_tensor = pool1,filters=n_filter*2,kernal_size(2,2),batch_normalization=batch_normalization)\n",
    "    pool2 = layers.MaxPool2D((2,2))(conv2)\n",
    "    pool2 = layers.Dropout(dropout)(pool2)\n",
    "    \n",
    "    conv3 = encoding_base_block(input_tensor = pool2,filters=n_filter*4,kernal_size(2,2),batch_normalization=batch_normalization)\n",
    "    pool3 = layers.MaxPool2D((2,2))(conv3)\n",
    "    pool3 = layers.Dropout(dropout)(pool3)\n",
    "    \n",
    "    conv4 = encoding_base_block(input_tensor = pool3,filters=n_filter*8,kernal_size(2,2),batch_normalization=batch_normalization)\n",
    "    pool4 = layers.MaxPool2D((2,2))(conv4)\n",
    "    pool4 = layers.Dropout(dropout)(pool4)\n",
    "    \n",
    "    conv5 = encoding_base_block(input_tensor=pool4,filters=n_filter*16,kernal_size=(2,2),batch_normalization=batch_normalization)\n",
    "    \n",
    "    output = pool1\n",
    "    \n",
    "    model = Model(inputs = [image_tensor],outputs = [output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
